{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "PXculM1gGSmI",
        "MzQpwCUzbhb4"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e1761b6a33da4528b3de7811d1d9f197": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_1f79db832a9344b0acc2dda4906a75dc",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "proc \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">proc <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "1f79db832a9344b0acc2dda4906a75dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "062a8ebbdf8f4a7894611587a8096969": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_84e816a844424c04a307779d76254fd7",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "proc \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">proc <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "84e816a844424c04a307779d76254fd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfd87edec2134e8692b867fae6b2647c": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_784b3def214e4bb790966761302befb3",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "proc \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">proc <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "784b3def214e4bb790966761302befb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csabi0312/crypto-svm/blob/gru/crypto14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXculM1gGSmI"
      },
      "source": [
        "# Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPoZWYEvnklQ",
        "outputId": "fd128c91-448f-4576-af2a-fae01f8d91d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAHz6AVhjOkb",
        "outputId": "83803ff0-53f9-4d30-87f6-2413119eb6c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.8/dist-packages (1.2.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (7.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.25.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (23.0)\n",
            "Requirement already satisfied: tensorflow>=2.0 in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (1.0.4)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.14.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.19.6)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.3.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (15.0.6.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.30.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.51.1)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.21.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (23.1.21)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.0.10)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.18.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.14.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (5.7.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=2.0->keras-tuner) (0.38.4)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (2.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (6.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.13.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install minisom"
      ],
      "metadata": {
        "id": "NP0Q2kfBbthj",
        "outputId": "2498c509-c81c-46aa-ae67-5e6c849e30c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: minisom in /usr/local/lib/python3.8/dist-packages (2.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install umap-learn"
      ],
      "metadata": {
        "id": "bDIkwtYNJscX",
        "outputId": "53c6cc11-9812-4a7d-dac1-1e2f6e902db6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.8/dist-packages (0.5.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from umap-learn) (1.21.6)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.8/dist-packages (from umap-learn) (0.56.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from umap-learn) (4.64.1)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.8/dist-packages (from umap-learn) (0.5.8)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.8/dist-packages (from umap-learn) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.8/dist-packages (from umap-learn) (1.7.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.49->umap-learn) (6.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.49->umap-learn) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.49->umap-learn) (0.39.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from pynndescent>=0.5->umap-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22->umap-learn) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.49->umap-learn) (3.13.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EVvqt5I_nobg"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import gzip\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.integrate import simps\n",
        "from numpy import trapz\n",
        "import pickle\n",
        "import gzip\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.integrate import simps\n",
        "from numpy import trapz\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC  \n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import keras.losses\n",
        "import sklearn\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, average_precision_score\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import keras_tuner\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.models import load_model\n",
        "import umap\n",
        "import datetime\n",
        "\n",
        "import datetime\n",
        "from sklearn.metrics import mean_squared_error as mse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_yHVZaHnp_z",
        "outputId": "222d8ac3-95a6-42fa-fd62-80180102a1a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.8/dist-packages (13.3.1)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from rich) (2.1.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.14.0 in /usr/local/lib/python3.8/dist-packages (from rich) (2.14.0)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from rich) (4.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.8/dist-packages (from markdown-it-py<3.0.0,>=2.1.0->rich) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install rich"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hSgNf7pKnv1o"
      },
      "outputs": [],
      "source": [
        "from rich.progress import track"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA"
      ],
      "metadata": {
        "id": "8Ly0xN4Bee6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw = pd.read_csv(\"/content/drive/MyDrive/Crypto/new3/full_spread_data.csv\",parse_dates = [\"Date\"], index_col = \"Date\").dropna()\n",
        "raw[\"returns\"] =np.log(raw.Close / raw.Close.shift(1))\n",
        "raw[\"Volume\"]=raw[\"Volume USDT\"]\n",
        "raw.drop([\"Open\",\"Unix\",\"Symbol\",\"Volume USDT\",\"Volume BTC\",\"tradecount\"],axis=1,inplace=True)\n",
        "raw"
      ],
      "metadata": {
        "id": "52pubRtT6x0r",
        "outputId": "c807661a-a801-4433-d879-c673e3146939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                High       Low     Close   returns        Volume\n",
              "Date                                                            \n",
              "2023-02-12  22090.00  21630.00  21783.54       NaN  4.469822e+09\n",
              "2023-02-11  21906.32  21599.78  21862.55  0.003620  3.842001e+09\n",
              "2023-02-10  21938.16  21451.00  21625.19 -0.010916  7.369456e+09\n",
              "2023-02-09  23011.39  21688.00  21796.35  0.007884  9.052973e+09\n",
              "2023-02-08  23452.00  22665.85  22963.00  0.052142  6.457586e+09\n",
              "...              ...       ...       ...       ...           ...\n",
              "2017-08-21   4119.62   3911.79   4016.00 -0.005958  2.797232e+06\n",
              "2017-08-20   4211.08   4032.62   4086.29  0.017351  1.930364e+06\n",
              "2017-08-19   4184.69   3850.00   4139.98  0.013053  1.549484e+06\n",
              "2017-08-18   4371.52   3938.77   4108.37 -0.007665  5.086958e+06\n",
              "2017-08-17   4485.39   4200.74   4285.08  0.042113  3.454770e+06\n",
              "\n",
              "[2006 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c41592a-24e3-4236-9e65-dcdad502dc3a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>returns</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-02-12</th>\n",
              "      <td>22090.00</td>\n",
              "      <td>21630.00</td>\n",
              "      <td>21783.54</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.469822e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-11</th>\n",
              "      <td>21906.32</td>\n",
              "      <td>21599.78</td>\n",
              "      <td>21862.55</td>\n",
              "      <td>0.003620</td>\n",
              "      <td>3.842001e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-10</th>\n",
              "      <td>21938.16</td>\n",
              "      <td>21451.00</td>\n",
              "      <td>21625.19</td>\n",
              "      <td>-0.010916</td>\n",
              "      <td>7.369456e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-09</th>\n",
              "      <td>23011.39</td>\n",
              "      <td>21688.00</td>\n",
              "      <td>21796.35</td>\n",
              "      <td>0.007884</td>\n",
              "      <td>9.052973e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-08</th>\n",
              "      <td>23452.00</td>\n",
              "      <td>22665.85</td>\n",
              "      <td>22963.00</td>\n",
              "      <td>0.052142</td>\n",
              "      <td>6.457586e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-21</th>\n",
              "      <td>4119.62</td>\n",
              "      <td>3911.79</td>\n",
              "      <td>4016.00</td>\n",
              "      <td>-0.005958</td>\n",
              "      <td>2.797232e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-20</th>\n",
              "      <td>4211.08</td>\n",
              "      <td>4032.62</td>\n",
              "      <td>4086.29</td>\n",
              "      <td>0.017351</td>\n",
              "      <td>1.930364e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-19</th>\n",
              "      <td>4184.69</td>\n",
              "      <td>3850.00</td>\n",
              "      <td>4139.98</td>\n",
              "      <td>0.013053</td>\n",
              "      <td>1.549484e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-18</th>\n",
              "      <td>4371.52</td>\n",
              "      <td>3938.77</td>\n",
              "      <td>4108.37</td>\n",
              "      <td>-0.007665</td>\n",
              "      <td>5.086958e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-17</th>\n",
              "      <td>4485.39</td>\n",
              "      <td>4200.74</td>\n",
              "      <td>4285.08</td>\n",
              "      <td>0.042113</td>\n",
              "      <td>3.454770e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2006 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c41592a-24e3-4236-9e65-dcdad502dc3a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9c41592a-24e3-4236-9e65-dcdad502dc3a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9c41592a-24e3-4236-9e65-dcdad502dc3a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw = pd.read_csv(\"/content/drive/MyDrive/Crypto/new3/full_spread_data.csv\",parse_dates = [\"Date\"], index_col = \"Date\").dropna()\n",
        "raw[\"returns\"] =np.log(raw.Close / raw.Close.shift(1))\n",
        "raw[\"Volume\"]=raw[\"Volume USDT\"]\n",
        "raw.drop([\"Open\",\"Unix\",\"Symbol\",\"Volume USDT\",\"Volume BTC\",\"tradecount\"],axis=1,inplace=True)\n",
        "cols = []\n",
        "for lag in range(1, 31):\n",
        "    col_h = \"h_lag{}\".format(lag)\n",
        "    col_l = \"l_lag{}\".format(lag)\n",
        "    col_r = \"c_lag{}\".format(lag)\n",
        "    col_v = \"v_lag{}\".format(lag)\n",
        "    raw[col_h] = raw.High.shift(lag)\n",
        "    cols.append(col_h)\n",
        "    raw[col_l] = raw.Low.shift(lag)\n",
        "    cols.append(col_l)\n",
        "    raw[col_r] = raw.Close.shift(lag)\n",
        "    cols.append(col_r)\n",
        "    raw[col_v] = raw.Volume.shift(lag)\n",
        "    cols.append(col_v)\n",
        "    raw.dropna(inplace = True)\n",
        "raw.drop([\"High\",\"Low\",\"Volume\",\"Close\"],axis=1,inplace=True)\n",
        "\n",
        "raw[\"returns2\"]=(raw[\"returns\"]>=0).astype(int)\n",
        "\n",
        "to=int(len(raw)*0.8)\n",
        "X_train=raw.drop([\"returns2\",\"returns\"],axis=1).iloc[:to].to_numpy()\n",
        "y_train=raw[\"returns2\"].iloc[:to].to_numpy().astype(int)\n",
        "X_test=raw.drop([\"returns2\",\"returns\"],axis=1).iloc[to:].to_numpy()\n",
        "y_test=raw[\"returns2\"].iloc[to:].to_numpy().astype(int)\n",
        "\n",
        "scaler1 = MinMaxScaler()\n",
        "X_train=scaler1.fit_transform(X_train)\n",
        "X_test=scaler1.transform(X_test)\n",
        "\n",
        "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miYfHBSKh-88",
        "outputId": "a65b9541-8ef0-40c2-b3e1-e8a026388097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1232, 120) (1232,) (309, 120) (309,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM + LightGBM"
      ],
      "metadata": {
        "id": "U4Bsnx9AEGtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "lgb_model = lgb.LGBMRegressor( n_estimators=100).fit(X_train,y_train)\n",
        "pred_test=(lgb_model.predict(X_test)>=0.5).astype(int)\n",
        "pred_train=(lgb_model.predict(X_train)>=0.5).astype(int)\n",
        "\n",
        "print(confusion_matrix(y_train,pred_train))\n",
        "print(classification_report(y_train,pred_train))\n",
        "print(confusion_matrix(y_test,pred_test))\n",
        "print(classification_report(y_test,pred_test))"
      ],
      "metadata": {
        "id": "ieN8JlyaELAG",
        "outputId": "48a1b698-54ba-492d-9168-d9e0213c5ccc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[500   0]\n",
            " [  0 448]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       500\n",
            "           1       1.00      1.00      1.00       448\n",
            "\n",
            "    accuracy                           1.00       948\n",
            "   macro avg       1.00      1.00      1.00       948\n",
            "weighted avg       1.00      1.00      1.00       948\n",
            "\n",
            "[[37 92]\n",
            " [36 73]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.29      0.37       129\n",
            "           1       0.44      0.67      0.53       109\n",
            "\n",
            "    accuracy                           0.46       238\n",
            "   macro avg       0.47      0.48      0.45       238\n",
            "weighted avg       0.48      0.46      0.44       238\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test"
      ],
      "metadata": {
        "id": "wnnp31N_ELE2",
        "outputId": "f21f3ef2-9abd-44d0-9357-30709e8edefe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.54752454, 0.38572366, 0.69755214, 0.41958138, 0.51828301,\n",
              "       0.5971246 , 0.40509583, 0.64213972, 0.32384628, 0.4591769 ,\n",
              "       0.50545099, 0.40969747, 0.49082563, 0.6291927 , 0.61186227,\n",
              "       0.58458019, 0.43367882, 0.55201088, 0.39858915, 0.52671543,\n",
              "       0.58708653, 0.58419125, 0.74714254, 0.43518183, 0.63715272,\n",
              "       0.55661731, 0.55471786, 0.52771813, 0.74060085, 0.56727685,\n",
              "       0.35188993, 0.61182057, 0.32460493, 0.48826276, 0.58737025,\n",
              "       0.52631554, 0.38983464, 0.55081881, 0.41142058, 0.51096897,\n",
              "       0.5122758 , 0.59789955, 0.52844535, 0.43311669, 0.45062899,\n",
              "       0.59981731, 0.46801126, 0.5312004 , 0.58954081, 0.79203048,\n",
              "       0.66268121, 0.64560692, 0.52457527, 0.61802072, 0.29893923,\n",
              "       0.14267367, 0.36826348, 0.31365825, 0.22425186, 0.40825181,\n",
              "       0.380961  , 0.64948147, 0.46184441, 0.41995819, 0.48273241,\n",
              "       0.6381088 , 0.35674206, 0.39047539, 0.47319918, 0.55857622,\n",
              "       0.41239789, 0.42897002, 0.65285795, 0.70837386, 0.535903  ,\n",
              "       0.46657217, 0.47052281, 0.48556325, 0.56317787, 0.47259922,\n",
              "       0.59384687, 0.55795757, 0.62433747, 0.38601185, 0.57987784,\n",
              "       0.63224097, 0.4935519 , 0.58243582, 0.33300199, 0.24359285,\n",
              "       0.48680089, 0.38921781, 0.40574241, 0.53771108, 0.30308564,\n",
              "       0.56956287, 0.67298982, 0.33290878, 0.75306134, 0.54250388,\n",
              "       0.37978127, 0.47332022, 0.46284078, 0.44854885, 0.62238407,\n",
              "       0.47467554, 0.63310927, 0.52024427, 0.36269323, 0.35472839,\n",
              "       0.45973757, 0.47894198, 0.55320367, 0.61907816, 0.4235062 ,\n",
              "       0.62243362, 0.57407619, 0.54993444, 0.6149376 , 0.6885387 ,\n",
              "       0.60922889, 0.66094326, 0.56335429, 0.519476  , 0.53243231,\n",
              "       0.40525934, 0.53164745, 0.61504546, 0.57452532, 0.66574283,\n",
              "       0.74664486, 0.68325088, 0.6641441 , 0.62246642, 0.50524222,\n",
              "       0.65264116, 0.42865066, 0.65468756, 0.54293715, 0.46493004,\n",
              "       0.5390921 , 0.57885542, 0.56419981, 0.61092894, 0.54032025,\n",
              "       0.48912263, 0.49216398, 0.53944442, 0.62256811, 0.6288658 ,\n",
              "       0.5941723 , 0.54407171, 0.64377031, 0.58682064, 0.46350723,\n",
              "       0.39715666, 0.41519934, 0.37994981, 0.38928006, 0.39046146,\n",
              "       0.49912028, 0.6959438 , 0.6441206 , 0.71076773, 0.59915212,\n",
              "       0.72928409, 0.59983776, 0.58137857, 0.71394858, 0.61086395,\n",
              "       0.64844823, 0.55641391, 0.5820329 , 0.59109892, 0.59026473,\n",
              "       0.53326247, 0.59154753, 0.63500117, 0.63500117, 0.53515851,\n",
              "       0.50562926, 0.53018203, 0.53018203, 0.5773306 , 0.5773306 ,\n",
              "       0.69036219, 0.58968379, 0.57918298, 0.55036084, 0.55036084,\n",
              "       0.50390753, 0.50390753, 0.46257618, 0.46257618, 0.46257618,\n",
              "       0.46257618, 0.46257618, 0.4923874 , 0.58404763, 0.55475176,\n",
              "       0.55475176, 0.55475176, 0.55475176, 0.58404763, 0.58404763,\n",
              "       0.58404763, 0.51253929, 0.54232117, 0.51253929, 0.54232117,\n",
              "       0.61362933, 0.54232117, 0.58404763, 0.58404763, 0.58404763,\n",
              "       0.54232117, 0.54232117, 0.57183357, 0.57838902, 0.6191365 ,\n",
              "       0.60604094, 0.6304302 , 0.56869036, 0.53423191, 0.53828123,\n",
              "       0.57887589, 0.6191365 , 0.6191365 , 0.64319235, 0.54317907,\n",
              "       0.50844417, 0.53651486, 0.50844417, 0.58404763, 0.58404763,\n",
              "       0.58404763, 0.58404763, 0.61279046])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vF74fIznELHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CAU5wp59ELJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA + SVM"
      ],
      "metadata": {
        "id": "-8q74k50DXcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw = pd.read_csv(\"/content/drive/MyDrive/Crypto/new3/full_spread_data.csv\",parse_dates = [\"Date\"], index_col = \"Date\").dropna()\n",
        "raw[\"returns\"] =np.log(raw.Close / raw.Close.shift(1))\n",
        "raw[\"Volume\"]=raw[\"Volume USDT\"]\n",
        "raw.drop([\"Open\",\"Unix\",\"Symbol\",\"Volume USDT\",\"Volume BTC\",\"tradecount\"],axis=1,inplace=True)\n",
        "cols = []\n",
        "for lag in range(1, 41):\n",
        "    col_h = \"h_lag{}\".format(lag)\n",
        "    col_l = \"l_lag{}\".format(lag)\n",
        "    col_r = \"c_lag{}\".format(lag)\n",
        "    col_v = \"v_lag{}\".format(lag)\n",
        "    raw[col_h] = raw.High.shift(lag)\n",
        "    cols.append(col_h)\n",
        "    raw[col_l] = raw.Low.shift(lag)\n",
        "    cols.append(col_l)\n",
        "    raw[col_r] = raw.Close.shift(lag)\n",
        "    cols.append(col_r)\n",
        "    raw[col_v] = raw.Volume.shift(lag)\n",
        "    cols.append(col_v)\n",
        "    raw.dropna(inplace = True)\n",
        "raw.drop([\"High\",\"Low\",\"Volume\",\"Close\"],axis=1,inplace=True)\n",
        "\n",
        "raw[\"returns2\"]=(raw[\"returns\"]>=0).astype(int)\n",
        "\n",
        "to=int(len(raw)*0.8)\n",
        "X_train=raw.drop([\"returns2\",\"returns\"],axis=1).iloc[:to].to_numpy()\n",
        "y_train=raw[\"returns2\"].iloc[:to].to_numpy().astype(int)\n",
        "X_test=raw.drop([\"returns2\",\"returns\"],axis=1).iloc[to:].to_numpy()\n",
        "y_test=raw[\"returns2\"].iloc[to:].to_numpy().astype(int)\n",
        "\n",
        "scaler1 = StandardScaler()\n",
        "X_train=scaler1.fit_transform(X_train)\n",
        "X_test=scaler1.transform(X_test)\n",
        "\n",
        "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Load the dataset\n",
        "\n",
        "\n",
        "# Perform PCA to reduce the dimensionality of the dataset\n",
        "reducer = umap.UMAP(n_components=30)\n",
        "X_reduced = reducer.fit_transform(X_train)\n",
        "X_reduced_test = reducer.transform(X_test)"
      ],
      "metadata": {
        "id": "LM4TcT07DdBt",
        "outputId": "d5563b8e-010c-4392-828f-2a90965af250",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(948, 160) (948,) (238, 160) (238,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define the SVM classifier\n",
        "svm = SVC()\n",
        "\n",
        "# Define the grid of hyperparameters to search\n",
        "param_grid = {'C': [0.3],\n",
        "              'gamma': [\"scale\",\"auto\"],\n",
        "              'kernel': [\"rbf\"]}\n",
        "\n",
        "# Perform grid search to tune the hyperparameters of the SVM\n",
        "grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
        "grid_search.fit(X_reduced, y_train)\n",
        "\n",
        "# The best hyperparameters found by grid search\n",
        "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# The best score achieved by the grid search\n",
        "print(\"Best score:\", grid_search.best_score_)\n",
        "\n",
        "# The best estimator found by the grid search\n",
        "best_svm = grid_search.best_estimator_\n",
        "\n",
        "# Predict the class labels for the reduced dataset\n",
        "y_pred_train = best_svm.predict(X_reduced)\n",
        "y_pred_test = best_svm.predict(X_reduced_test)\n",
        "\n",
        "# Print the classification accuracy\n",
        "print(\"Classification accuracy:\", np.mean(y_pred_train == y_train))\n",
        "print(\"Classification accuracy:\", np.mean(y_pred_test == y_test))\n"
      ],
      "metadata": {
        "id": "CrsLOGCZDdUM",
        "outputId": "9c9c0000-778d-47c9-ec98-c2a295157747",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'C': 0.3, 'gamma': 'auto', 'kernel': 'rbf'}\n",
            "Best score: 0.5063102199944305\n",
            "Classification accuracy: 0.54957805907173\n",
            "Classification accuracy: 0.542016806722689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc=[]\n",
        "test_acc=[]\n",
        "ossz=[]\n",
        "\n",
        "reducer = umap.UMAP(n_components=2)\n",
        "X_reduced = reducer.fit_transform(X_train)\n",
        "X_reduced_test = reducer.transform(X_test)\n",
        "a=0.1\n",
        "b=2\n",
        "gran=0.05\n",
        "for c in np.arange(a,b,gran):\n",
        "  svm = SVC()\n",
        "\n",
        "  # Define the grid of hyperparameters to search\n",
        "  param_grid = {'C': [c],\n",
        "                'gamma': [\"scale\"],\n",
        "                'kernel': [\"rbf\"]}\n",
        "\n",
        "  # Perform grid search to tune the hyperparameters of the SVM\n",
        "  grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
        "  grid_search.fit(X_reduced, y_train)\n",
        "\n",
        "  # The best hyperparameters found by grid search\n",
        "  print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "  # The best score achieved by the grid search\n",
        "  print(\"Best score:\", grid_search.best_score_)\n",
        "\n",
        "  # The best estimator found by the grid search\n",
        "  best_svm = grid_search.best_estimator_\n",
        "\n",
        "  # Predict the class labels for the reduced dataset\n",
        "  y_pred_train = best_svm.predict(X_reduced)\n",
        "  y_pred_test = best_svm.predict(X_reduced_test)\n",
        "\n",
        "  # Print the classification accuracy\n",
        "  train_acc.append(1-np.mean(y_pred_train == y_train))\n",
        "  test_acc.append(1-np.mean(y_pred_test == y_test))\n",
        "  ossz.append(train_acc[-1]+test_acc[-1])\n",
        "plt.plot(np.arange(a,b,gran),train_acc,color=\"blue\")\n",
        "plt.plot(np.arange(a,b,gran),test_acc,color=\"red\")\n",
        "#plt.plot(np.arange(a,b,gran),ossz,\"g-\")\n",
        "plt.plot(np.arange(a,b,gran),0.5*np.ones(len(np.arange(a,b,gran))),color=\"purple\")"
      ],
      "metadata": {
        "id": "047SieNaB0Qr",
        "outputId": "38a1c11a-69cf-4b7e-cca9-d5d511f28cf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.5274296853244221\n",
            "Best hyperparameters: {'C': 0.15000000000000002, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.48844890002784735\n",
            "Best hyperparameters: {'C': 0.20000000000000004, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.5042105263157894\n",
            "Best hyperparameters: {'C': 0.25000000000000006, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.5073684210526315\n",
            "Best hyperparameters: {'C': 0.30000000000000004, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.5052631578947369\n",
            "Best hyperparameters: {'C': 0.3500000000000001, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.5063157894736842\n",
            "Best hyperparameters: {'C': 0.40000000000000013, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.5052631578947369\n",
            "Best hyperparameters: {'C': 0.45000000000000007, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.5052631578947369\n",
            "Best hyperparameters: {'C': 0.5000000000000001, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.5063157894736842\n",
            "Best hyperparameters: {'C': 0.5500000000000002, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.5063157894736842\n",
            "Best hyperparameters: {'C': 0.6000000000000002, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.5063157894736842\n",
            "Best hyperparameters: {'C': 0.6500000000000001, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.5063157894736842\n",
            "Best hyperparameters: {'C': 0.7000000000000002, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.5063157894736842\n",
            "Best hyperparameters: {'C': 0.7500000000000002, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.5063157894736842\n",
            "Best hyperparameters: {'C': 0.8000000000000002, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.5063157894736842\n",
            "Best hyperparameters: {'C': 0.8500000000000002, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.5063157894736842\n",
            "Best hyperparameters: {'C': 0.9000000000000002, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.5063157894736842\n",
            "Best hyperparameters: {'C': 0.9500000000000003, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.5063157894736842\n",
            "Best hyperparameters: {'C': 1.0000000000000004, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.5063157894736842\n",
            "Best hyperparameters: {'C': 1.0500000000000003, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.5073684210526315\n",
            "Best hyperparameters: {'C': 1.1000000000000005, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.4999610136452241\n",
            "Best hyperparameters: {'C': 1.1500000000000004, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.4999610136452241\n",
            "Best hyperparameters: {'C': 1.2000000000000004, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.4978446115288221\n",
            "Best hyperparameters: {'C': 1.2500000000000004, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.497844611528822\n",
            "Best hyperparameters: {'C': 1.3000000000000005, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.4957282094124199\n",
            "Best hyperparameters: {'C': 1.3500000000000005, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.4946700083542188\n",
            "Best hyperparameters: {'C': 1.4000000000000006, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.4936118072960178\n",
            "Best hyperparameters: {'C': 1.4500000000000006, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.4904372041214146\n",
            "Best hyperparameters: {'C': 1.5000000000000004, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.4925536062378167\n",
            "Best hyperparameters: {'C': 1.5500000000000005, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.4925536062378167\n",
            "Best hyperparameters: {'C': 1.6000000000000005, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.4946644388749652\n",
            "Best hyperparameters: {'C': 1.6500000000000006, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.49360623781676416\n",
            "Best hyperparameters: {'C': 1.7000000000000006, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.4946644388749652\n",
            "Best hyperparameters: {'C': 1.7500000000000007, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.49254803675856307\n",
            "Best hyperparameters: {'C': 1.8000000000000007, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.490431634642161\n",
            "Best hyperparameters: {'C': 1.8500000000000008, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.490431634642161\n",
            "Best hyperparameters: {'C': 1.9000000000000008, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.48514062935115565\n",
            "Best hyperparameters: {'C': 1.9500000000000006, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best score: 0.4840824282929546\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f24c937c040>]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# svm"
      ],
      "metadata": {
        "id": "uKj6NbVziE0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "Wz_jGwByj5Ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc=[]  \n",
        "test_acc=[]\n",
        "\n",
        "for num_lags in track(np.arange(30,40,1),description=\"proc\"):\n",
        "  raw = pd.read_csv(\"/content/drive/MyDrive/Crypto/new3/full_spread_data.csv\", parse_dates = [\"time\"], index_col = \"time\").dropna()\n",
        "  raw[\"returns\"] =np.log(raw.Close / raw.Close.shift(1))\n",
        "  raw[\"returns2\"]=(raw[\"returns\"]>=0).astype(int)\n",
        "  raw.drop([\"Open\",\"Spread\",\"Close\",\"High\",\"returns\",\"Volume\",\"Low\"],axis=1,inplace=True)\n",
        "  cols = []\n",
        "  for lag in range(1, num_lags):\n",
        "      col_r = \"r_lag{}\".format(lag)\n",
        "      raw[col_r] = raw.returns2.shift(lag)\n",
        "  raw.dropna(inplace = True)\n",
        "\n",
        "  to=int(len(raw)*0.8)\n",
        "  X_train=raw.drop([\"returns2\"],axis=1).iloc[:to].to_numpy()\n",
        "  y_train=raw[\"returns2\"].iloc[:to].to_numpy().astype(int)\n",
        "  X_test=raw.drop([\"returns2\"],axis=1).iloc[to:].to_numpy()\n",
        "  y_test=raw[\"returns2\"].iloc[to:].to_numpy().astype(int)\n",
        "\n",
        "  clf = svm.SVC(kernel=\"rbf\")\n",
        "  clf.fit(X_train,y_train)\n",
        "  pred_test=clf.predict(X_test)\n",
        "  pred_train=clf.predict(X_train)\n",
        "\n",
        "  train_acc.append(1-accuracy_score(y_train,pred_train))\n",
        "  test_acc.append(1-accuracy_score(y_test,pred_test))\n",
        "plt.plot(np.arange(30,40,1),train_acc,color=\"blue\")\n",
        "plt.plot(np.arange(30,40,1),test_acc,color=\"red\")\n",
        "plt.plot(np.arange(30,40,1),0.5*np.ones(10),color=\"purple\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "e1761b6a33da4528b3de7811d1d9f197",
            "1f79db832a9344b0acc2dda4906a75dc"
          ]
        },
        "id": "5-nOSM3qPmnj",
        "outputId": "a0bc2c54-9df6-48d6-f1c7-c60d650fd211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1761b6a33da4528b3de7811d1d9f197"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f36ba84a910>]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm"
      ],
      "metadata": {
        "id": "EU2V2nOviGsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw = pd.read_csv(\"/content/drive/MyDrive/Crypto/new3/full_spread_data.csv\", parse_dates = [\"time\"], index_col = \"time\").dropna()\n",
        "raw[\"returns\"] =np.log(raw.Close / raw.Close.shift(1))\n",
        "raw[\"returns2\"]=(raw[\"returns\"]>=0).astype(int)\n",
        "raw.drop([\"Open\",\"Spread\",\"Close\",\"High\",\"returns\",\"Volume\",\"Low\"],axis=1,inplace=True)\n",
        "cols = []\n",
        "for lag in range(1, 34):\n",
        "    col_r = \"r_lag{}\".format(lag)\n",
        "    raw[col_r] = raw.returns2.shift(lag)\n",
        "raw.dropna(inplace = True)\n",
        "to=int(len(raw)*0.8)\n",
        "X_train=raw.drop([\"returns2\"],axis=1).iloc[:to].to_numpy()\n",
        "y_train=raw[\"returns2\"].iloc[:to].to_numpy().astype(int)\n",
        "X_test=raw.drop([\"returns2\"],axis=1).iloc[to:].to_numpy()\n",
        "y_test=raw[\"returns2\"].iloc[to:].to_numpy().astype(int)\n",
        "\n",
        "\n",
        "clf = svm.SVC(kernel=\"rbf\")\n",
        "clf.fit(X_train,y_train)\n",
        "pred_sign=clf.predict(X_test)\n",
        "pred_train=clf.predict(X_train)\n",
        "print(confusion_matrix(y_train,pred_train))\n",
        "print(classification_report(y_train,pred_train))\n",
        "print(confusion_matrix(y_test,pred_sign))\n",
        "print(classification_report(y_test,pred_sign))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqPb90GaiH5K",
        "outputId": "9739c943-c3b6-4626-aeae-96d70233344b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[469 266]\n",
            " [ 42 875]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.64      0.75       735\n",
            "           1       0.77      0.95      0.85       917\n",
            "\n",
            "    accuracy                           0.81      1652\n",
            "   macro avg       0.84      0.80      0.80      1652\n",
            "weighted avg       0.83      0.81      0.81      1652\n",
            "\n",
            "[[ 74 141]\n",
            " [ 58 141]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.34      0.43       215\n",
            "           1       0.50      0.71      0.59       199\n",
            "\n",
            "    accuracy                           0.52       414\n",
            "   macro avg       0.53      0.53      0.51       414\n",
            "weighted avg       0.53      0.52      0.50       414\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# random forest"
      ],
      "metadata": {
        "id": "88HCKruPmmq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "EM7r7jW4mmrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc=[]  \n",
        "test_acc=[]\n",
        "\n",
        "for num_lags in track(np.arange(2,20,1),description=\"proc\"):\n",
        "  raw = pd.read_csv(\"/content/drive/MyDrive/Crypto/new3/full_spread_data.csv\",parse_dates = [\"Date\"], index_col = \"Date\").dropna()\n",
        "  raw[\"returns\"] =np.log(raw.Close / raw.Close.shift(1))\n",
        "  raw[\"Volume\"]=raw[\"Volume USDT\"]\n",
        "  raw[\"returns2\"]=(raw[\"returns\"]>=0).astype(int)\n",
        "  raw.drop([\"Open\",\"Unix\",\"Symbol\",\"Volume USDT\",\"Volume BTC\",\"tradecount\",\"returns\"],axis=1,inplace=True)\n",
        "  cols = []\n",
        "  for lag in range(1, num_lags):\n",
        "      col_r = \"r_lag{}\".format(lag)\n",
        "      raw[col_r] = raw.returns2.shift(lag)\n",
        "  raw.dropna(inplace = True)\n",
        "\n",
        "  to=int(len(raw)*0.8)\n",
        "  X_train=raw.drop([\"returns2\"],axis=1).iloc[:to].to_numpy()\n",
        "  y_train=raw[\"returns2\"].iloc[:to].to_numpy().astype(int)\n",
        "  X_test=raw.drop([\"returns2\"],axis=1).iloc[to:].to_numpy()\n",
        "  y_test=raw[\"returns2\"].iloc[to:].to_numpy().astype(int)\n",
        "\n",
        "  clf = RandomForestClassifier()\n",
        "  clf.fit(X_train,y_train)\n",
        "  pred_test=clf.predict(X_test)\n",
        "  pred_train=clf.predict(X_train)\n",
        "\n",
        "  train_acc.append(1-accuracy_score(y_train,pred_train))\n",
        "  test_acc.append(1-accuracy_score(y_test,pred_test))\n",
        "plt.plot(np.arange(2,20,1),train_acc,color=\"blue\")\n",
        "plt.plot(np.arange(2,20,1),test_acc,color=\"red\")\n",
        "plt.plot(np.arange(2,20,1),0.5*np.ones(18),color=\"purple\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "062a8ebbdf8f4a7894611587a8096969",
            "84e816a844424c04a307779d76254fd7"
          ]
        },
        "outputId": "2e1e757e-46d1-49cf-cb38-295eb5975c70",
        "id": "VG2-eQNRmmrB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "062a8ebbdf8f4a7894611587a8096969"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9e14b0bc10>]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# logstic regression"
      ],
      "metadata": {
        "id": "H4eXholenb6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "I21l57WJnb6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc=[]  \n",
        "test_acc=[]\n",
        "a=2\n",
        "b=65\n",
        "for num_lags in track(np.arange(a,b,1),description=\"proc\"):\n",
        "  raw = pd.read_csv(\"/content/drive/MyDrive/Crypto/new3/full_spread_data.csv\",parse_dates = [\"Date\"], index_col = \"Date\").dropna()\n",
        "  raw[\"returns\"] =np.log(raw.Close / raw.Close.shift(1))\n",
        "  raw[\"Volume\"]=raw[\"Volume USDT\"]\n",
        "  raw[\"returns2\"]=(raw[\"returns\"]>=0).astype(int)\n",
        "  raw.drop([\"Open\",\"Unix\",\"Symbol\",\"Volume USDT\",\"Volume BTC\",\"tradecount\",\"returns\"],axis=1,inplace=True)\n",
        "  cols = []\n",
        "  for lag in range(1, num_lags):\n",
        "      col_r = \"r_lag{}\".format(lag)\n",
        "      raw[col_r] = raw.returns2.shift(lag)\n",
        "  raw.dropna(inplace = True)\n",
        "\n",
        "  to=int(len(raw)*0.8)\n",
        "  X_train=raw.drop([\"returns2\"],axis=1).iloc[:to].to_numpy()\n",
        "  y_train=raw[\"returns2\"].iloc[:to].to_numpy().astype(int)\n",
        "  X_test=raw.drop([\"returns2\"],axis=1).iloc[to:].to_numpy()\n",
        "  y_test=raw[\"returns2\"].iloc[to:].to_numpy().astype(int)\n",
        "\n",
        "  clf = LogisticRegression()\n",
        "  clf.fit(X_train,y_train)\n",
        "  pred_test=clf.predict(X_test)\n",
        "  pred_train=clf.predict(X_train)\n",
        "\n",
        "  train_acc.append(1-accuracy_score(y_train,pred_train))\n",
        "  test_acc.append(1-accuracy_score(y_test,pred_test))\n",
        "plt.plot(np.arange(a,b,1),train_acc,color=\"blue\")\n",
        "plt.plot(np.arange(a,b,1),test_acc,color=\"red\")\n",
        "plt.plot(np.arange(a,b,1),0.5*np.ones(b-a),color=\"purple\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "bfd87edec2134e8692b867fae6b2647c",
            "784b3def214e4bb790966761302befb3"
          ]
        },
        "outputId": "b47e13ef-00d9-40ca-fc75-20d964b47226",
        "id": "Cl-qnNVSnb6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bfd87edec2134e8692b867fae6b2647c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9e148998b0>]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw = pd.read_csv(\"/content/drive/MyDrive/Crypto/new3/full_spread_data.csv\", parse_dates = [\"time\"], index_col = \"time\").dropna()\n",
        "raw[\"returns\"] =np.log(raw.Close / raw.Close.shift(1))\n",
        "raw[\"returns2\"]=(raw[\"returns\"]>=0).astype(int)\n",
        "raw.drop([\"Open\",\"Spread\",\"Close\",\"High\",\"returns\",\"Volume\",\"Low\"],axis=1,inplace=True)\n",
        "cols = []\n",
        "for lag in range(1, 40):\n",
        "    col_r = \"r_lag{}\".format(lag)\n",
        "    raw[col_r] = raw.returns2.shift(lag)\n",
        "raw.dropna(inplace = True)\n",
        "to=int(len(raw)*0.8)\n",
        "X_train=raw.drop([\"returns2\"],axis=1).iloc[:to].to_numpy()\n",
        "y_train=raw[\"returns2\"].iloc[:to].to_numpy().astype(int)\n",
        "X_test=raw.drop([\"returns2\"],axis=1).iloc[to:].to_numpy()\n",
        "y_test=raw[\"returns2\"].iloc[to:].to_numpy().astype(int)\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X_train,y_train)\n",
        "pred_test=clf.predict(X_test)\n",
        "pred_train=clf.predict(X_train)\n",
        "\n",
        "print(confusion_matrix(y_train,pred_train))\n",
        "print(classification_report(y_train,pred_train))\n",
        "print(confusion_matrix(y_test,pred_test))\n",
        "print(classification_report(y_test,pred_test))"
      ],
      "metadata": {
        "id": "wnL_AwTnn-BK",
        "outputId": "029ac3a5-a306-4186-fa7d-3fa289f9b4f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[252 480]\n",
            " [172 744]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.34      0.44       732\n",
            "           1       0.61      0.81      0.70       916\n",
            "\n",
            "    accuracy                           0.60      1648\n",
            "   macro avg       0.60      0.58      0.57      1648\n",
            "weighted avg       0.60      0.60      0.58      1648\n",
            "\n",
            "[[ 83 132]\n",
            " [ 63 134]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.39      0.46       215\n",
            "           1       0.50      0.68      0.58       197\n",
            "\n",
            "    accuracy                           0.53       412\n",
            "   macro avg       0.54      0.53      0.52       412\n",
            "weighted avg       0.54      0.53      0.52       412\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GRU2"
      ],
      "metadata": {
        "id": "134l3zG0Yg8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw = pd.read_csv(\"/content/drive/MyDrive/Crypto/new3/full_spread_data.csv\",parse_dates = [\"Date\"], index_col = \"Date\").dropna()\n",
        "raw[\"returns\"] =np.log(raw.Close / raw.Close.shift(1))\n",
        "raw[\"Volume\"]=raw[\"Volume USDT\"]\n",
        "raw.drop([\"Open\",\"Unix\",\"Symbol\",\"Volume USDT\",\"Volume BTC\",\"tradecount\"],axis=1,inplace=True)\n",
        "cols = []\n",
        "for lag in range(1, 31):\n",
        "    col_h = \"h_lag{}\".format(lag)\n",
        "    col_l = \"l_lag{}\".format(lag)\n",
        "    col_r = \"c_lag{}\".format(lag)\n",
        "    col_v = \"v_lag{}\".format(lag)\n",
        "    raw[col_h] = raw.High.shift(lag)\n",
        "    cols.append(col_h)\n",
        "    raw[col_l] = raw.Low.shift(lag)\n",
        "    cols.append(col_l)\n",
        "    raw[col_r] = raw.Close.shift(lag)\n",
        "    cols.append(col_r)\n",
        "    raw[col_v] = raw.Volume.shift(lag)\n",
        "    cols.append(col_v)\n",
        "    raw.dropna(inplace = True)\n",
        "raw.drop([\"High\",\"Low\",\"Volume\",\"Close\"],axis=1,inplace=True)\n",
        "\n",
        "raw[\"returns2\"]=(raw[\"returns\"]>=0).astype(int)\n",
        "\n",
        "to=int(len(raw)*0.8)\n",
        "X_train=raw.drop([\"returns2\",\"returns\"],axis=1).iloc[:to].to_numpy()\n",
        "y_train=raw[\"returns2\"].iloc[:to].to_numpy().astype(int)\n",
        "X_test=raw.drop([\"returns2\",\"returns\"],axis=1).iloc[to:].to_numpy()\n",
        "y_test=raw[\"returns2\"].iloc[to:].to_numpy().astype(int)\n",
        "\n",
        "scaler1 = MinMaxScaler()\n",
        "X_train=scaler1.fit_transform(X_train)\n",
        "X_test=scaler1.transform(X_test)\n",
        "\n",
        "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train2 = to_categorical(y_train, 2)\n",
        "y_test2 = to_categorical(y_test, 2)\n",
        "\n",
        "X_train=X_train.reshape(len(X_train),30,4)\n",
        "X_test=X_test.reshape(len(X_test),30,4)\n",
        "\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    #model.add(GRU(hp.Int('units1', min_value=5, max_value=200, step=1),activation=\"tanh\",input_shape=(30,4),return_sequences=True))\n",
        "    model.add(LSTM(hp.Int('units2', min_value=128, max_value=128, step=1),activation=\"tanh\",return_sequences=True))\n",
        "    model.add(LSTM(hp.Int('units21', min_value=256, max_value=256, step=1),activation=\"tanh\",return_sequences=False))\n",
        "    model.add(Dense(2,activation=\"softmax\"))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "#tuner = keras_tuner.RandomSearch(\n",
        "#      build_model,\n",
        "#      objective='val_loss',\n",
        "#      max_trials=1,overwrite = True)\n",
        "#tuner.search(X_train,y_train2 , epochs=1,batch_size=32, validation_split=0.2)\n",
        "\n",
        "\n",
        "def build_model_best():\n",
        "    model = Sequential()\n",
        "    model.add(GRU(128,activation=\"tanh\",input_shape=(30,4),return_sequences=True))\n",
        "    model.add(GRU(128,activation=\"tanh\",input_shape=(30,4),return_sequences=True))\n",
        "    model.add(LSTM(128,activation=\"tanh\",return_sequences=True))\n",
        "    model.add(LSTM(256,activation=\"tanh\",return_sequences=False))\n",
        "    model.add(Dense(2,activation=\"softmax\"))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "best_model = build_model_best()\n",
        "\n",
        "early_stopping=EarlyStopping(patience=200, verbose=0)\n",
        "#checkpointer=ModelCheckpoint(filepath='weights1.hdf5', save_best_only=True, verbose=1)\n",
        "best_model.fit(X_train,y_train2, batch_size=64,epochs=1000, verbose=1, \\\n",
        "                validation_split=0.2,callbacks=[ early_stopping], shuffle=True)\n",
        "\n",
        "predictions =best_model.predict(X_test)\n",
        "pred_sign=np.argmax(predictions,axis=1)\n",
        "pred_train=np.argmax(best_model.predict(X_train),axis=1)\n",
        "true_sign=np.argmax(y_test2,axis=1)\n",
        "print(confusion_matrix(np.argmax(y_train2,axis=1),pred_train))\n",
        "print(confusion_matrix(true_sign,pred_sign))\n",
        "print(classification_report(true_sign,pred_sign))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "470hqXnrtOBl",
        "outputId": "a857daa3-ad19-4ebf-dc1d-3a57e9b00c99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1232, 120) (1232,) (309, 120) (309,)\n",
            "Epoch 1/1000\n",
            "16/16 [==============================] - 69s 4s/step - loss: 0.7101 - accuracy: 0.5036 - val_loss: 0.6934 - val_accuracy: 0.5061\n",
            "Epoch 2/1000\n",
            "16/16 [==============================] - 63s 4s/step - loss: 0.6927 - accuracy: 0.5360 - val_loss: 0.6934 - val_accuracy: 0.5061\n",
            "Epoch 3/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6915 - accuracy: 0.5360 - val_loss: 0.6936 - val_accuracy: 0.5061\n",
            "Epoch 4/1000\n",
            "16/16 [==============================] - 60s 4s/step - loss: 0.6909 - accuracy: 0.5360 - val_loss: 0.6937 - val_accuracy: 0.5061\n",
            "Epoch 5/1000\n",
            "16/16 [==============================] - 63s 4s/step - loss: 0.6910 - accuracy: 0.5360 - val_loss: 0.6941 - val_accuracy: 0.5061\n",
            "Epoch 6/1000\n",
            "16/16 [==============================] - 61s 4s/step - loss: 0.6908 - accuracy: 0.5360 - val_loss: 0.6950 - val_accuracy: 0.5061\n",
            "Epoch 7/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6913 - accuracy: 0.5360 - val_loss: 0.6944 - val_accuracy: 0.5061\n",
            "Epoch 8/1000\n",
            "16/16 [==============================] - 61s 4s/step - loss: 0.6914 - accuracy: 0.5360 - val_loss: 0.6936 - val_accuracy: 0.5061\n",
            "Epoch 9/1000\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.6918 - accuracy: 0.5360 - val_loss: 0.6943 - val_accuracy: 0.5061\n",
            "Epoch 10/1000\n",
            "16/16 [==============================] - 63s 4s/step - loss: 0.6913 - accuracy: 0.5360 - val_loss: 0.6943 - val_accuracy: 0.5061\n",
            "Epoch 11/1000\n",
            "16/16 [==============================] - 62s 4s/step - loss: 0.6908 - accuracy: 0.5360 - val_loss: 0.6938 - val_accuracy: 0.5061\n",
            "Epoch 12/1000\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.6911 - accuracy: 0.5371 - val_loss: 0.6940 - val_accuracy: 0.5061\n",
            "Epoch 13/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6910 - accuracy: 0.5360 - val_loss: 0.6944 - val_accuracy: 0.5061\n",
            "Epoch 14/1000\n",
            "16/16 [==============================] - 66s 4s/step - loss: 0.6910 - accuracy: 0.5360 - val_loss: 0.6943 - val_accuracy: 0.5061\n",
            "Epoch 15/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6907 - accuracy: 0.5360 - val_loss: 0.6946 - val_accuracy: 0.5061\n",
            "Epoch 16/1000\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.6908 - accuracy: 0.5360 - val_loss: 0.6949 - val_accuracy: 0.5061\n",
            "Epoch 17/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6907 - accuracy: 0.5360 - val_loss: 0.6949 - val_accuracy: 0.5061\n",
            "Epoch 18/1000\n",
            "16/16 [==============================] - 62s 4s/step - loss: 0.6910 - accuracy: 0.5360 - val_loss: 0.6947 - val_accuracy: 0.5061\n",
            "Epoch 19/1000\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.6905 - accuracy: 0.5360 - val_loss: 0.6953 - val_accuracy: 0.5061\n",
            "Epoch 20/1000\n",
            "16/16 [==============================] - 67s 4s/step - loss: 0.6905 - accuracy: 0.5360 - val_loss: 0.6949 - val_accuracy: 0.5061\n",
            "Epoch 21/1000\n",
            "16/16 [==============================] - 66s 4s/step - loss: 0.6905 - accuracy: 0.5360 - val_loss: 0.6956 - val_accuracy: 0.5061\n",
            "Epoch 22/1000\n",
            "16/16 [==============================] - 67s 4s/step - loss: 0.6907 - accuracy: 0.5360 - val_loss: 0.6949 - val_accuracy: 0.5061\n",
            "Epoch 23/1000\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.6908 - accuracy: 0.5360 - val_loss: 0.6950 - val_accuracy: 0.5061\n",
            "Epoch 24/1000\n",
            "16/16 [==============================] - 62s 4s/step - loss: 0.6907 - accuracy: 0.5360 - val_loss: 0.6948 - val_accuracy: 0.5061\n",
            "Epoch 25/1000\n",
            "16/16 [==============================] - 63s 4s/step - loss: 0.6908 - accuracy: 0.5391 - val_loss: 0.6950 - val_accuracy: 0.5061\n",
            "Epoch 26/1000\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.6902 - accuracy: 0.5381 - val_loss: 0.6967 - val_accuracy: 0.5061\n",
            "Epoch 27/1000\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.6908 - accuracy: 0.5360 - val_loss: 0.6956 - val_accuracy: 0.5061\n",
            "Epoch 28/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6906 - accuracy: 0.5391 - val_loss: 0.6954 - val_accuracy: 0.5061\n",
            "Epoch 29/1000\n",
            "16/16 [==============================] - 66s 4s/step - loss: 0.6949 - accuracy: 0.5391 - val_loss: 0.6935 - val_accuracy: 0.5061\n",
            "Epoch 30/1000\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.6925 - accuracy: 0.5350 - val_loss: 0.6938 - val_accuracy: 0.5061\n",
            "Epoch 31/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6913 - accuracy: 0.5360 - val_loss: 0.6941 - val_accuracy: 0.5061\n",
            "Epoch 32/1000\n",
            "16/16 [==============================] - 62s 4s/step - loss: 0.6920 - accuracy: 0.5360 - val_loss: 0.6940 - val_accuracy: 0.5061\n",
            "Epoch 33/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6915 - accuracy: 0.5360 - val_loss: 0.6943 - val_accuracy: 0.5061\n",
            "Epoch 34/1000\n",
            "16/16 [==============================] - 61s 4s/step - loss: 0.6909 - accuracy: 0.5360 - val_loss: 0.6945 - val_accuracy: 0.5061\n",
            "Epoch 35/1000\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.6907 - accuracy: 0.5360 - val_loss: 0.6949 - val_accuracy: 0.5061\n",
            "Epoch 36/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6906 - accuracy: 0.5360 - val_loss: 0.6949 - val_accuracy: 0.5061\n",
            "Epoch 37/1000\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.6907 - accuracy: 0.5360 - val_loss: 0.6953 - val_accuracy: 0.5061\n",
            "Epoch 38/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6907 - accuracy: 0.5360 - val_loss: 0.6941 - val_accuracy: 0.5061\n",
            "Epoch 39/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6907 - accuracy: 0.5360 - val_loss: 0.6945 - val_accuracy: 0.5061\n",
            "Epoch 40/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6906 - accuracy: 0.5360 - val_loss: 0.6947 - val_accuracy: 0.5061\n",
            "Epoch 41/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6907 - accuracy: 0.5360 - val_loss: 0.6947 - val_accuracy: 0.5061\n",
            "Epoch 42/1000\n",
            "16/16 [==============================] - 62s 4s/step - loss: 0.6905 - accuracy: 0.5360 - val_loss: 0.6948 - val_accuracy: 0.5061\n",
            "Epoch 43/1000\n",
            "16/16 [==============================] - 62s 4s/step - loss: 0.6906 - accuracy: 0.5360 - val_loss: 0.6952 - val_accuracy: 0.5061\n",
            "Epoch 44/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6905 - accuracy: 0.5360 - val_loss: 0.6963 - val_accuracy: 0.5061\n",
            "Epoch 45/1000\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.6906 - accuracy: 0.5360 - val_loss: 0.6960 - val_accuracy: 0.5061\n",
            "Epoch 46/1000\n",
            "16/16 [==============================] - 62s 4s/step - loss: 0.6915 - accuracy: 0.5360 - val_loss: 0.6961 - val_accuracy: 0.5061\n",
            "Epoch 47/1000\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.6908 - accuracy: 0.5360 - val_loss: 0.6950 - val_accuracy: 0.5061\n",
            "Epoch 48/1000\n",
            "16/16 [==============================] - 62s 4s/step - loss: 0.6910 - accuracy: 0.5360 - val_loss: 0.6955 - val_accuracy: 0.5061\n",
            "Epoch 49/1000\n",
            "16/16 [==============================] - 66s 4s/step - loss: 0.6908 - accuracy: 0.5360 - val_loss: 0.6950 - val_accuracy: 0.5061\n",
            "Epoch 50/1000\n",
            "16/16 [==============================] - 66s 4s/step - loss: 0.6905 - accuracy: 0.5360 - val_loss: 0.6952 - val_accuracy: 0.5061\n",
            "Epoch 51/1000\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.6912 - accuracy: 0.5360 - val_loss: 0.6955 - val_accuracy: 0.5061\n",
            "Epoch 52/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6905 - accuracy: 0.5360 - val_loss: 0.6954 - val_accuracy: 0.5061\n",
            "Epoch 53/1000\n",
            "16/16 [==============================] - 61s 4s/step - loss: 0.6905 - accuracy: 0.5360 - val_loss: 0.6948 - val_accuracy: 0.5061\n",
            "Epoch 54/1000\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.6907 - accuracy: 0.5360 - val_loss: 0.6950 - val_accuracy: 0.5061\n",
            "Epoch 55/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6905 - accuracy: 0.5360 - val_loss: 0.6946 - val_accuracy: 0.5061\n",
            "Epoch 56/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6905 - accuracy: 0.5360 - val_loss: 0.6948 - val_accuracy: 0.5061\n",
            "Epoch 57/1000\n",
            "16/16 [==============================] - 60s 4s/step - loss: 0.6905 - accuracy: 0.5360 - val_loss: 0.6949 - val_accuracy: 0.5061\n",
            "Epoch 58/1000\n",
            "16/16 [==============================] - 63s 4s/step - loss: 0.6904 - accuracy: 0.5360 - val_loss: 0.6951 - val_accuracy: 0.5061\n",
            "Epoch 59/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6905 - accuracy: 0.5360 - val_loss: 0.6948 - val_accuracy: 0.5061\n",
            "Epoch 60/1000\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.6907 - accuracy: 0.5360 - val_loss: 0.6949 - val_accuracy: 0.5061\n",
            "Epoch 61/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6909 - accuracy: 0.5360 - val_loss: 0.6958 - val_accuracy: 0.5061\n",
            "Epoch 62/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6906 - accuracy: 0.5360 - val_loss: 0.6950 - val_accuracy: 0.5061\n",
            "Epoch 63/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6905 - accuracy: 0.5360 - val_loss: 0.6950 - val_accuracy: 0.5061\n",
            "Epoch 64/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6908 - accuracy: 0.5360 - val_loss: 0.6947 - val_accuracy: 0.5061\n",
            "Epoch 65/1000\n",
            "16/16 [==============================] - 66s 4s/step - loss: 0.6903 - accuracy: 0.5360 - val_loss: 0.6954 - val_accuracy: 0.5061\n",
            "Epoch 66/1000\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.6905 - accuracy: 0.5360 - val_loss: 0.6960 - val_accuracy: 0.5061\n",
            "Epoch 67/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6903 - accuracy: 0.5360 - val_loss: 0.6959 - val_accuracy: 0.5061\n",
            "Epoch 68/1000\n",
            "16/16 [==============================] - 63s 4s/step - loss: 0.6902 - accuracy: 0.5371 - val_loss: 0.6951 - val_accuracy: 0.5061\n",
            "Epoch 69/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6901 - accuracy: 0.5371 - val_loss: 0.6951 - val_accuracy: 0.5061\n",
            "Epoch 70/1000\n",
            "16/16 [==============================] - 61s 4s/step - loss: 0.6901 - accuracy: 0.5360 - val_loss: 0.6955 - val_accuracy: 0.5061\n",
            "Epoch 71/1000\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.6896 - accuracy: 0.5310 - val_loss: 0.7020 - val_accuracy: 0.4899\n",
            "Epoch 72/1000\n",
            "16/16 [==============================] - 63s 4s/step - loss: 0.8183 - accuracy: 0.5066 - val_loss: 1.2640 - val_accuracy: 0.4939\n",
            "Epoch 73/1000\n",
            "16/16 [==============================] - 63s 4s/step - loss: 0.7985 - accuracy: 0.4985 - val_loss: 0.6936 - val_accuracy: 0.5061\n",
            "Epoch 74/1000\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.6945 - accuracy: 0.5157 - val_loss: 0.6931 - val_accuracy: 0.5061\n",
            "Epoch 75/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.7018 - accuracy: 0.4985 - val_loss: 0.6932 - val_accuracy: 0.5061\n",
            "Epoch 76/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6944 - accuracy: 0.5056 - val_loss: 0.6994 - val_accuracy: 0.5061\n",
            "Epoch 77/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6962 - accuracy: 0.4893 - val_loss: 0.6953 - val_accuracy: 0.5061\n",
            "Epoch 78/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6946 - accuracy: 0.5360 - val_loss: 0.6942 - val_accuracy: 0.5061\n",
            "Epoch 79/1000\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.6953 - accuracy: 0.5015 - val_loss: 0.6958 - val_accuracy: 0.5061\n",
            "Epoch 80/1000\n",
            "16/16 [==============================] - 67s 4s/step - loss: 0.6930 - accuracy: 0.5360 - val_loss: 0.6968 - val_accuracy: 0.5061\n",
            "Epoch 81/1000\n",
            "16/16 [==============================] - 61s 4s/step - loss: 0.6925 - accuracy: 0.5360 - val_loss: 0.6939 - val_accuracy: 0.5061\n",
            "Epoch 82/1000\n",
            "16/16 [==============================] - 63s 4s/step - loss: 0.6920 - accuracy: 0.5360 - val_loss: 0.6951 - val_accuracy: 0.5061\n",
            "Epoch 83/1000\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.6934 - accuracy: 0.4954 - val_loss: 0.6949 - val_accuracy: 0.5061\n",
            "Epoch 84/1000\n",
            "16/16 [==============================] - 63s 4s/step - loss: 0.6938 - accuracy: 0.5360 - val_loss: 0.6957 - val_accuracy: 0.5061\n",
            "Epoch 85/1000\n",
            "16/16 [==============================] - 62s 4s/step - loss: 0.6910 - accuracy: 0.5360 - val_loss: 0.6939 - val_accuracy: 0.5061\n",
            "Epoch 86/1000\n",
            " 6/16 [==========>...................] - ETA: 37s - loss: 0.6865 - accuracy: 0.5703"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc=[]  \n",
        "test_acc=[]\n",
        "a=7\n",
        "b=61\n",
        "num_lag=a\n",
        "while num_lag<b:\n",
        "  raw = pd.read_csv(\"/content/drive/MyDrive/Crypto/new3/full_spread_data.csv\", parse_dates = [\"time\"], index_col = \"time\").dropna()\n",
        "  raw[\"returns\"] =np.log(raw.Close / raw.Close.shift(1))\n",
        "  raw[\"returns2\"]=(raw[\"returns\"]>=0).astype(int)\n",
        "  raw.drop([\"Open\",\"Spread\",\"Close\",\"High\",\"returns\",\"Volume\",\"Low\"],axis=1,inplace=True)\n",
        "  cols = []\n",
        "  for lag in range(1, num_lag):\n",
        "      col_r = \"r_lag{}\".format(lag)\n",
        "      raw[col_r] = raw.returns2.shift(lag)\n",
        "  raw.dropna(inplace = True)\n",
        "  to=int(len(raw)*0.8)\n",
        "  X_train=raw.drop([\"returns2\"],axis=1).iloc[:to].to_numpy()\n",
        "  y_train=raw[\"returns2\"].iloc[:to].to_numpy().astype(int)\n",
        "  X_test=raw.drop([\"returns2\"],axis=1).iloc[to:].to_numpy()\n",
        "  y_test=raw[\"returns2\"].iloc[to:].to_numpy().astype(int)\n",
        "\n",
        "  from tensorflow.keras.utils import to_categorical\n",
        "  y_train2 = to_categorical(y_train, 2)\n",
        "  y_test2 = to_categorical(y_test, 2)\n",
        "\n",
        "\n",
        "  def build_model(hp):\n",
        "      model = Sequential()\n",
        "      model.add(Dense(hp.Int('units1', min_value=5, max_value=200, step=1),activation=\"relu\",input_shape=(num_lag-1,1)))\n",
        "      model.add(Dense(hp.Int('units2', min_value=5, max_value=180, step=1),activation=\"relu\"))\n",
        "      model.add(Dense(hp.Int('units3', min_value=5, max_value=160, step=1),activation=\"relu\"))\n",
        "      model.add(Dense(hp.Int('units4', min_value=5, max_value=140, step=1),activation=\"relu\"))\n",
        "      model.add(Dense(hp.Int('units5', min_value=5, max_value=120, step=1),activation=\"relu\"))\n",
        "      model.add(GRU(hp.Int('units5', min_value=5, max_value=120, step=1),activation=\"tanh\",return_sequences=True))\n",
        "      model.add(LSTM(hp.Int('units5', min_value=5, max_value=120, step=1),activation=\"tanh\"))\n",
        "      model.add(Dense(2,activation=\"softmax\"))\n",
        "\n",
        "      model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "      return model\n",
        "\n",
        "  tuner = keras_tuner.RandomSearch(\n",
        "        build_model,\n",
        "        objective='val_loss',\n",
        "        max_trials=10,overwrite = True)\n",
        "  tuner.search(X_train,y_train2 , epochs=5, validation_split=0.2)\n",
        "  best_model = tuner.get_best_models()[0]\n",
        "  best_model.summary()\n",
        "\n",
        "  early_stopping=EarlyStopping(patience=10, verbose=0)\n",
        "  checkpointer=ModelCheckpoint(filepath='weights1.hdf5', save_best_only=True, verbose=1)\n",
        "  best_model.fit(X_train,y_train2, batch_size=50,epochs=100, verbose=0, \\\n",
        "                  validation_split=0.2,callbacks=[checkpointer, early_stopping], shuffle=True)\n",
        "\n",
        "  predictions =best_model.predict(X_test)\n",
        "  predistions2=best_model.predict(X_train)\n",
        "  pred_test=np.argmax(predictions,axis=1)\n",
        "  pred_train=np.argmax(predistions2,axis=1)\n",
        "  train_acc.append(1-accuracy_score(y_train,pred_train))\n",
        "  test_acc.append(1-accuracy_score(y_test,pred_test))\n",
        "  num_lag+=1\n",
        "\n",
        "plt.plot(np.arange(a,b,1),train_acc,color=\"blue\")\n",
        "plt.plot(np.arange(a,b,1),test_acc,color=\"red\")\n",
        "plt.plot(np.arange(a,b,1),0.5*np.ones(b-a),color=\"purple\")"
      ],
      "metadata": {
        "id": "lLox0gxqpctg",
        "outputId": "8ba1060c-6f8d-4f6a-c81b-f00e106c95e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 12s]\n",
            "val_loss: 0.6848078966140747\n",
            "\n",
            "Best val_loss So Far: 0.6833024621009827\n",
            "Total elapsed time: 00h 02m 12s\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 59, 47)            94        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 59, 170)           8160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 59, 33)            5643      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 59, 103)           3502      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 59, 9)             936       \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 59, 9)             540       \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 9)                 684       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19,579\n",
            "Trainable params: 19,579\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.68430, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.68430\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.68430\n",
            "\n",
            "Epoch 4: val_loss improved from 0.68430 to 0.68387, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.68387\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.68387\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.68387\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.68387\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.68387\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.68387\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.68387\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.68387\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.68387\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.68387\n",
            "13/13 [==============================] - 1s 5ms/step\n",
            "51/51 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb3ff31ae80>]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GvMzySjJpdTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JUbK01ZTpdWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_sign=-(predictions>=0).astype(int)+(predictions<0).astype(int)\n",
        "true_sign=(y_true>=0).astype(int)-(y_true<0).astype(int)\n",
        "print(confusion_matrix(true_sign,pred_sign))\n",
        "print(classification_report(true_sign,pred_sign))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0b3m3PGN5YS",
        "outputId": "1cb956f2-3aa3-4fdf-9483-70cba7f83847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[215  75]\n",
            " [216  92]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.50      0.74      0.60       290\n",
            "           1       0.55      0.30      0.39       308\n",
            "\n",
            "    accuracy                           0.51       598\n",
            "   macro avg       0.52      0.52      0.49       598\n",
            "weighted avg       0.53      0.51      0.49       598\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlvadTSx1sDc",
        "outputId": "eb6788d8-992f-444a-e8bd-fe2e864466c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(598, 56)"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmR_a4E4azq7"
      },
      "source": [
        "# GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7u6MIsEm89h"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(LSTM(hp.Int('units2', min_value=1, max_value=200, step=1), return_sequences=True, input_shape=(60,1)))\n",
        "    model.add(GRU(hp.Int('units2', min_value=1, max_value=200, step=1), return_sequences=True))\n",
        "    model.add(LSTM(hp.Int('units2', min_value=1, max_value=200, step=1), return_sequences=False))\n",
        "    model.add(Dense(hp.Int('units3', min_value=5, max_value=100, step=1)))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=[tf.keras.metrics.MeanSquaredError()])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = keras_tuner.RandomSearch(\n",
        "      build_model,\n",
        "      objective='val_loss',\n",
        "      max_trials=10,overwrite = True)\n",
        "tuner.search(X_train,y_train , epochs=10, validation_split=0.2)\n",
        "best_model = tuner.get_best_models()[0]\n",
        "best_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fM9WingWIGXc",
        "outputId": "79068576-71b7-43f6-f9d7-c3cc5d6a9103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 11s]\n",
            "val_loss: 0.8127514123916626\n",
            "\n",
            "Best val_loss So Far: 0.8071630597114563\n",
            "Total elapsed time: 00h 02m 12s\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 60, 109)           48396     \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 60, 109)           71940     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 109)               95484     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 29)                3190      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 30        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 219,040\n",
            "Trainable params: 219,040\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnWc6F-oeFXX",
        "outputId": "c31635d2-1f31-4ee5-b81a-1bb8de63c3ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_loss improved from inf to 1.13291, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 2: val_loss did not improve from 1.13291\n",
            "\n",
            "Epoch 3: val_loss did not improve from 1.13291\n",
            "\n",
            "Epoch 4: val_loss improved from 1.13291 to 1.13181, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 5: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 6: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 7: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 8: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 9: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 10: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 11: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 12: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 13: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 14: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 15: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 16: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 17: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 18: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 19: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 20: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 21: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 22: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 23: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 24: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 25: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 26: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 27: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 28: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 29: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 30: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 31: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 32: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 33: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 34: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 35: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 36: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 37: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 38: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 39: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 40: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 41: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 42: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 43: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 44: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 45: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 46: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 47: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 48: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 49: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 50: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 51: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 52: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 53: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 54: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 55: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 56: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 57: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 58: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 59: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 60: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 61: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 62: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 63: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 64: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 65: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 66: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 67: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 68: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 69: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 70: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 71: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 72: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 73: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 74: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 75: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 76: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 77: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 78: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 79: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 80: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 81: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 82: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 83: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 84: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 85: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 86: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 87: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 88: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 89: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 90: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 91: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 92: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 93: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 94: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 95: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 96: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 97: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 98: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 99: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 100: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 101: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 102: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 103: val_loss did not improve from 1.13181\n",
            "\n",
            "Epoch 104: val_loss did not improve from 1.13181\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f23c0719220>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "#best_model=build_best()\n",
        "early_stopping=EarlyStopping(patience=100, verbose=0)\n",
        "checkpointer=ModelCheckpoint(filepath='weights1.hdf5', save_best_only=True, verbose=1)\n",
        "best_model.fit(X_train,y_train, batch_size=32,epochs=1000, verbose=0, \\\n",
        "                validation_split=0.1,callbacks=[checkpointer, early_stopping], shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = scaler2.inverse_transform(best_model.predict(X_test)).flatten()\n",
        "y_true=scaler2.inverse_transform(y_test.reshape(-1,1)).flatten()\n",
        "pred_sign=(predictions>=0).astype(int)-(predictions<0).astype(int)\n",
        "true_sign=(y_true>=0).astype(int)-(y_true<0).astype(int)\n",
        "print(confusion_matrix(true_sign,pred_sign))\n",
        "print(classification_report(true_sign,pred_sign))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hIQiud6nxNF",
        "outputId": "68e6625c-f3ac-4844-8b1d-b7067c2c0bb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 9ms/step\n",
            "[[11 12]\n",
            " [21 10]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.34      0.48      0.40        23\n",
            "           1       0.45      0.32      0.38        31\n",
            "\n",
            "    accuracy                           0.39        54\n",
            "   macro avg       0.40      0.40      0.39        54\n",
            "weighted avg       0.41      0.39      0.39        54\n",
            "\n"
          ]
        }
      ]
    }
  ]
}